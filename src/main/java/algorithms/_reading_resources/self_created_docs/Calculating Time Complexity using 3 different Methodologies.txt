Calculating Time Complexity Using 3 different approaches
--------------------------------------------------------

Methods
- Iterative algorithms time complexity can be solved using 
	Back Substitution
- Recursive algorithms time complexity can be solved using 
	Back Substitution Method   ---- slow but easy
	Recursive Tree Method	  ---- slow and complex.  
	Master's theorem Method	  ---- fast
	

(1+2+3+.....+n) = (n(n+1) / 2) 			= O(n^2)
n+(n-1)+(n-2)+....+1 = (n(n+1) / 2) 	= O(n^2)
n^K + (n^k-1) + (n^k-2) + ......+  		= O(n^k)
1 + 1/2 + 1/3 + 1/4 + ...... 1/n 		= log n

For recursive algorithms, when assume k levels and then assume n=2^k. 
if n=2^k, then k= log n with base 2
if n=3^k, then k= log n with base 3
if n=5^k, then k= log n with base 5 and so on


Calculating Time Complexity for Iterative algorithms
-----------------------------------------------------
https://www.youtube.com/watch?v=FEnwM-iDb2g
1)
for(i=1; i<=n; i++)
	for(j=1; i<=n; i++)

Time taken = O(n^2)

2)
for(i=1; i<=n; i++)
	for(j=1; i<=i; j++)
		for(k=1; k<=100; k++)

i=1				i=2				i=3				i=n
j=1 time		j=2 times		j=3 times		j=n times
k=100 time 		k=2*100 times	k=3*100 times	k=n*100 times

100+ 2*100 + 3*100 + ....+ n*100
100 (1+2+3+.....+n)
100 (n(n+1) / 2)
O(n^2) 

3)

for(i=1; i<=n; i=i*2)

n=1		i=2		i=3		i=4		 i=8
1 time	1 time	1 time	2 times  3 times
for n=2^k, loop will be executed k times
so, k= log n with base 2

for(i=1; i<=n; i=i++)	--- n
	for(j=1; j<=n; j=i*2) --- log n with base 2 as per above example

Time Taken = O(n log n)

If
for(i=1; i<=n; i=i++)	--- n
	for(j=1; j<=n; j=i*3) --- log n with base 3 as per above example



If 
for(i=1; i<=n; i=i++)	--- n
	for(j=1; j<=n/2; j=i*2) --- log n/2 with base 2 as per above example
	
Time Taken = O(n log n/2)


4)
for(i=1; i<=n; i=i++)	
	for(j=1; j<=n; j=j+i) 

Time taken = n + n/2 + n/3 + n/4 +......+1	
		   = n (1 + 1/2 + 1/3 + 1/4 + ...... 1/n)
		   =  O(n log n)
	
	
5)
while(n>1)
{
	n = n/2
}

n=2		n=4		n=8
1 time	2 times 4 times

n=2^k then loop will be executed k times
k=log n with base 2

while(n>1)
{
	n = n/3	--- log n with base 3
}
	
Calculating Time Complexity for Recursive algorithms
-----------------------------------------------------
https://www.youtube.com/watch?v=gCsfk2ei2R8

1)

	A(n) {
		if(n==1) return
		A(n/2)+A(n/2)
	}	

	T(n) = C (constant time for n==1 comparison) + 2T(n/2)   when n>1
	T(1) = O(1) ; when n==1

	T(n)   = C + 2T(n/2)
	T(n/2) = C + 2T(n/4)
	T(n/3) = C + 2T(n/8)

	T(n) = C + 2T(n/2)
		 = 2C + 4T(n/4)
		 = 3C + 8T(n/8)
		 = KC + 2^KT(n/2^K)
		 
		 To substitute T(n/2^k) to T(1)
		 n/2^k = 1
		 n = 2^k
		 k = log  n (log n of base 2)
				2

	T(n) = (log n)C + n*1
		 = log n  +  n
		 = O(n)	

https://www.youtube.com/watch?v=gCsfk2ei2R8
This is Recursive Tree Method
		 
					A(n)								
		A(n/2)					A(n/2)			C			= C  = 2^0 C
	A(n/4)	A(n/4) C		A(n/4)	A(n/4) C				= 2C = 2^1 C
															= 4C = 2^2 C
															= 8C = 2^3 C
															= (2^K)C (where K is a number of level)
															 

Total Time taken = 2^0 C + 2^1 C + 2^2 C + 2^3 C +.....+(2^K)C	(where K is a number of level)
				 = c(1(2^K+1  -  1)  / (2-1) ) ---- I don't know how this formula came
				 = c(2n - 1)
				 = O(n)
				 	

Back Substitution approach for Merge Sort,
		T(n) = 2n + 2T(n/2)
		T(n/2) = 2(n/2) + 2T(n/4)
			   = n + 2T(n/4)
		T(n/3) = 2(n/3) + 2T(n/6)
		T(n/4) = 2(n/4) + 2T(n/8)

		T(n) = 2n + 2T(n/2)
			 = 2n + 2(n + 2T(n/4))
			 = 4n + 4T(n/4)
			 = 4n + 4(2(n/4) + 2T(n/8))
			 = 6n+8T(n/8)
			 = (2*K*n)+(2^K)T(n/2^K)
		To substitute T(n/2^K) to T(1)
		n/2^K = 1
		n = 2^K
		K = log n with base 2

		T(n) = 2nlog n + n = O(n log n)

You can see Recursive approach for Merge Sort 
	
													divide(n)
			(n/2 time to create L array) 	(n/2 time to create R array) 	divide(L)	divide(R)	(n time to concur)  --- 2n time

			Like this each level in tree will take 2n time.					

			Each level in tree takes 2n time. 
			So, if there are K levels, then it takes 2n*K. 
			Assume n=2^K. So, K=log n with base 2
			So, 2n*K = 2n log n = O(nlog n)
	 
2) 	 

	A(n) {
		if(n==1) return
		A(n-1)
	}	  

	T(n)=C+T(n-1)  where C is time taken for n==1 comparison
	T(1)=O(1) ; when exit condition comes, it will take O(1)

	T(n-1) = C+T(n-2)
	T(n-2) = C+T(n-3)
	T(n)=C+(C+T(n-2))
		=C+(C+C+T(n-3))
		=3C+T(n-3)
		=KC+T(n-K)
	To make T(n-k)=T(1)
	n-k=1
	So, k = n-1
	T(n)=(n-1)C + T(1)
		=Cn - 1 + 1
		= O(n)

3)
	T(n) = n + T(n-1)
	T(1) = O(1) ; when exit condition comes(n==1), it will take O(1)
	
	T(n) = n + T(n-1)
	T(n-1) = (n-1) + T(n-2)
	T(n-2) = (n-2) + T(n-3)
	
	T(n) = n + T(n-1)
	T(n) = n + (n-1) + T(n-2)
	T(n) = n + (n-1) + (n-2) + T(n-3)
	T(n) = n + (n-1) + (n-2) + (n-3) + (n-4) + .....+(n-(k-1)) + T(n-k)
	To make T(n-k) = T(1)
	n-k=1
	k = n-1
	
	T(n) = n + (n-1) + (n-2) + (n-3) + (n-4) + .....+ (n-((n-1)-1)) + 1
		 = n + (n-1) + (n-2) + (n-3) + (n-4) + .....+ 2 + 1
		 = n(n+1) 				(REMEMBER THIS)
		   ------
		   	 2
		 = O(n^2)  	 


Master's Theorem

    https://www.geeksforgeeks.org/analysis-algorithm-set-4-master-method-solving-recurrences/

    T(n) = a T(n/b) + n^c,  where a>=1 and b>1

        if c < log a, then result is n ^ log a
                  b                         b
        if c = log a, then result is log a * n^c
                  b                     b
        if c > log a, then result is n^c
                  b

    e.g. MatrixMultiplication_divide_and_conquer.java, Merge Sort

        T(n) = 8 T(n/2) + n^2

             a = 8, b = 2, c = 2

             so, log a = log 8 = 3
                    b       2

             so, T(n) = n ^ log 8
                               2
                      = n ^ 3


	